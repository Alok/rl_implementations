{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Exercise 4 - Asynchronous Advantage Actor Critic\n",
    "\n",
    "**GOAL:** The goal of this exercise is to demonstrate how to use the asynchronous advantage actor critic (A3C) algorithm.\n",
    "\n",
    "A3C is described in detail in https://arxiv.org/abs/1602.01783.\n",
    "\n",
    "In A3C, the driver maintains the most up-to-date policy. It creates a number of actors which are used to compute perform partial rollouts and to compute gradient updates to the model. The driver runs in a loop in which it waits for a single actor task to finish, updates the model with the result of the actor task, and launches a new actor task with the updated model. Because the actor tasks may run in any order, the algorithm is fundamentally asynchronous and non-deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T04:38:15.623623Z",
     "start_time": "2018-03-29T04:38:04.469685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ray\n",
    "from ray.rllib.a3c import A3CAgent, DEFAULT_CONFIG\n",
    "from ray.rllib.a3c.shared_model import SharedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up Ray. This must be done before we instantiate any RL agents. We pass in `num_workers=0` because the training agent's constructor will create a number of actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T04:38:16.708136Z",
     "start_time": "2018-03-29T04:38:15.626948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for redis server at 127.0.0.1:41555 to respond...\n",
      "Waiting for redis server at 127.0.0.1:24990 to respond...\n",
      "Starting local scheduler with the following resources: {'CPU': 8, 'GPU': 0}.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8896/notebooks/ray_ui89423.ipynb?token=771da28f2c984ddb9bbac909cb1f94c797451ebd66e209da\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler60632477'],\n",
       " 'node_ip_address': '127.0.0.1',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store56774151', manager_name='/tmp/plasma_manager84457557', manager_port=31862)],\n",
       " 'redis_address': '127.0.0.1:41555',\n",
       " 'webui_url': 'http://localhost:8896/notebooks/ray_ui89423.ipynb?token=771da28f2c984ddb9bbac909cb1f94c797451ebd66e209da'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an A3CAgent object. We pass in a config object that specifies how the network and training procedure should be configured. Some of the parameters are the following.\n",
    "\n",
    "- `num_workers` is the number of actors that the agent will create. This determines the degree of parallelism that will be used.\n",
    "- `batch_size` is the number of simulator steps that each actor will batch together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T05:06:35.171435Z",
     "start_time": "2018-03-29T05:06:09.602997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Observation shape is (4,)\n",
      "Not using any observation preprocessor.\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Constructing fcnet [256, 256] <function tanh at 0x11fbfaf28>\n",
      "Setting up loss\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Observation shape is (2,)\n",
      "Not using any observation preprocessor.\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Constructing fcnet [256, 256] <function tanh at 0x11fbfaf28>\n",
      "Setting up loss\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 16\n",
    "config['batch_size'] = 16\n",
    "\n",
    "config_ = config.copy()\n",
    "agent = A3CAgent(config, 'CartPole-v0')\n",
    "agent_ = A3CAgent(config_, 'MountainCar-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Train the agent for some number of steps on the CartPole environment. Compare the performance to PPO from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T05:12:13.229677Z",
     "start_time": "2018-03-29T05:06:35.178462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/tune/logger.py:168: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(value, float):\n",
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/tune/logger.py:170: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(value, int):\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    result = agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Instantiate an A3CAgent object on the `MountainCar-v0` environment and train it for some number of steps. Compare the performance to PPO from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T05:14:44.811873Z",
     "start_time": "2018-03-29T05:12:13.239648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/tune/logger.py:168: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(value, float):\n",
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/tune/logger.py:170: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(value, int):\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    result_ = agent_.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T05:14:44.989291Z",
     "start_time": "2018-03-29T05:14:44.820091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.51111111111112------------------------------------------------------------------------\n",
      "-200.0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    result.episode_reward_mean,\n",
    "    result_.episode_reward_mean,\n",
    "    sep=72 * '-'+'\\n',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
