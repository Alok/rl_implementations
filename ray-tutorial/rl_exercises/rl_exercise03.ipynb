{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Exercise 3 - Proximal Policy Optimization\n",
    "\n",
    "**GOAL:** The goal of this exercise is to demonstrate how to use the proximal policy optimization (PPO) algorithm.\n",
    "\n",
    "PPO is described in detail in https://arxiv.org/abs/1707.06347. It is a variant of Trust Region Policy Optimization (TRPO) described in https://arxiv.org/abs/1502.05477\n",
    "\n",
    "PPO works in two phases. In one phase, a large number of rollouts are performed (in parallel). The rollouts are then aggregated on the driver and a surrogate optimization objective is defined based on those rollouts. We then use SGD to find the policy that maximizes that objective with a penalty term for diverging too much from the current policy.\n",
    "\n",
    "**NOTE:** The SGD optimization step is best performed in a data-parallel manner over multiple GPUs. This is exposed through the `devices` field of the `config` dictionary (for this to work, you must be using a machine that has GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:45:22.946030Z",
     "start_time": "2018-03-29T03:45:09.105604Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.ppo import PPOAgent, DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up Ray. This must be done before we instantiate any RL agents. We pass in `num_workers=0` because the training agent's constructor will create a number of actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:45:45.339232Z",
     "start_time": "2018-03-29T03:45:44.135154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for redis server at 127.0.0.1:56402 to respond...\n",
      "Waiting for redis server at 127.0.0.1:52600 to respond...\n",
      "Starting local scheduler with the following resources: {'CPU': 8, 'GPU': 0}.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8895/notebooks/ray_ui65673.ipynb?token=a04e05bf3ae4bb9dbae3a4b37ef0e91ff356d3cc284f32cf\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Perhaps you called ray.init twice by accident?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-97bafbe6c745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/ray/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(redis_address, node_ip_address, object_id_seed, num_workers, driver_mode, redirect_output, num_cpus, num_gpus, resources, num_custom_resource, num_redis_shards, redis_max_clients, plasma_directory, huge_pages, include_webui)\u001b[0m\n\u001b[1;32m   1467\u001b[0m                  \u001b[0mplasma_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplasma_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m                  \u001b[0mhuge_pages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhuge_pages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m                  include_webui=include_webui)\n\u001b[0m\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/ray/worker.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(address_info, start_ray_local, object_id_seed, num_workers, num_local_schedulers, object_store_memory, driver_mode, redirect_output, start_workers_from_local_scheduler, num_cpus, num_gpus, resources, num_redis_shards, redis_max_clients, plasma_directory, huge_pages, include_webui)\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \"webui_url\": address_info[\"webui_url\"]}\n\u001b[1;32m   1395\u001b[0m     connect(driver_address_info, object_id_seed=object_id_seed,\n\u001b[0;32m-> 1396\u001b[0;31m             mode=driver_mode, worker=global_worker, actor_id=NIL_ACTOR_ID)\n\u001b[0m\u001b[1;32m   1397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maddress_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(info, object_id_seed, mode, worker, actor_id)\u001b[0m\n\u001b[1;32m   1757\u001b[0m     \u001b[0;31m# Do some basic checking to make sure we didn't call ray.init twice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Perhaps you called ray.init twice by accident?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_functions_to_run\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_remote_functions_and_actors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Perhaps you called ray.init twice by accident?"
     ]
    }
   ],
   "source": [
    "ray.init(num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a PPOAgent object. We pass in a config object that specifies how the network and training procedure should be configured. Some of the parameters are the following.\n",
    "\n",
    "- `num_agents` is the number of actors that the agent will create. This determines the degree of parallelism that will be used.\n",
    "- `num_sgd_iter` is the number of epochs of SGD (passes through the data) that will be used to optimize the PPO surrogate objective at each iteration of PPO.\n",
    "- `sgd_batchsize` is the SGD batch size that will be used to optimize the PPO surrogate objective.\n",
    "- `model` contains a dictionary of parameters describing the neural net used to parameterize the policy. The `fcnet_hiddens` parameter is a list of the sizes of the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:46:13.879800Z",
     "start_time": "2018-03-29T03:46:10.928433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Observation shape is (4,)\n",
      "Not using any observation preprocessor.\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "WARNING:tensorflow:From /Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/rllib/models/action_dist.py:54: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/rllib/models/action_dist.py:59: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [100, 100] <function tanh at 0x11cf7f378>\n",
      "WARNING: Serializing objects of type <class 'ray.tune.registry._Registry'> by expanding them as dictionaries of their fields. This behavior may be incorrect in some cases.\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_batchsize'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "\n",
    "agent = PPOAgent(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the policy on the `CartPole-v0` environment for 2 steps. The CartPole problem is described at https://gym.openai.com/envs/CartPole-v0.\n",
    "\n",
    "**EXERCISE:** Inspect how well the policy is doing by looking for the lines that say something like\n",
    "\n",
    "```\n",
    "total reward is  22.3215974777\n",
    "trajectory length mean is  21.3215974777\n",
    "```\n",
    "\n",
    "This indicates how much reward the policy is receiving and how many time steps of the environment the policy ran. The maximum possible reward for this problem is 200. The reward and trajectory length are very close because the agent receives a reward of one for every time step that it survives (however, that is specific to this environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:47:07.662638Z",
     "start_time": "2018-03-29T03:46:58.090087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> iteration 4\n",
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    3.45683e+03    8.80492e-04    3.45683e+03    3.59236e-05    5.71446e-01\n",
      "              1    3.43720e+03    6.25133e-04    3.43720e+03    1.09336e-04    5.69045e-01\n",
      "              2    3.41699e+03    4.28345e-04    3.41699e+03    2.71533e-04    5.66235e-01\n",
      "              3    3.39670e+03    3.34345e-04    3.39670e+03    2.91015e-04    5.65247e-01\n",
      "              4    3.37699e+03    8.83215e-05    3.37699e+03    4.21387e-04    5.63902e-01\n",
      "              5    3.35746e+03   -7.62925e-05    3.35746e+03    5.40983e-04    5.63376e-01\n",
      "              6    3.33838e+03   -1.59915e-04    3.33838e+03    8.15238e-04    5.61826e-01\n",
      "              7    3.31956e+03   -3.14552e-04    3.31956e+03    7.72596e-04    5.60851e-01\n",
      "              8    3.30098e+03   -4.14943e-04    3.30098e+03    9.78424e-04    5.59300e-01\n",
      "              9    3.28277e+03   -5.21649e-04    3.28277e+03    8.16569e-04    5.60718e-01\n",
      "             10    3.26478e+03   -6.53717e-04    3.26478e+03    7.93861e-04    5.60359e-01\n",
      "             11    3.24698e+03   -7.25872e-04    3.24698e+03    9.54895e-04    5.58695e-01\n",
      "             12    3.22946e+03   -8.56644e-04    3.22946e+03    1.03686e-03    5.58634e-01\n",
      "             13    3.21210e+03   -1.04266e-03    3.21210e+03    1.17639e-03    5.58214e-01\n",
      "             14    3.19505e+03   -1.02616e-03    3.19505e+03    1.09281e-03    5.58417e-01\n",
      "             15    3.17810e+03   -1.14155e-03    3.17810e+03    1.14442e-03    5.58477e-01\n",
      "             16    3.16141e+03   -1.31002e-03    3.16141e+03    1.40208e-03    5.56742e-01\n",
      "             17    3.14484e+03   -1.29912e-03    3.14484e+03    1.39137e-03    5.57306e-01\n",
      "             18    3.12848e+03   -1.34686e-03    3.12848e+03    1.35360e-03    5.57146e-01\n",
      "             19    3.11227e+03   -1.53241e-03    3.11227e+03    1.39800e-03    5.57097e-01\n",
      "             20    3.09625e+03   -1.63629e-03    3.09625e+03    1.54538e-03    5.57636e-01\n",
      "             21    3.08035e+03   -1.74108e-03    3.08036e+03    1.47639e-03    5.57374e-01\n",
      "             22    3.06463e+03   -1.76002e-03    3.06463e+03    1.54236e-03    5.56934e-01\n",
      "             23    3.04901e+03   -1.82152e-03    3.04901e+03    1.58295e-03    5.57122e-01\n",
      "             24    3.03356e+03   -2.00838e-03    3.03356e+03    1.63821e-03    5.58115e-01\n",
      "             25    3.01827e+03   -2.08386e-03    3.01827e+03    1.75323e-03    5.57307e-01\n",
      "             26    3.00308e+03   -2.21223e-03    3.00308e+03    1.87020e-03    5.56929e-01\n",
      "             27    2.98799e+03   -2.14359e-03    2.98799e+03    1.76339e-03    5.58357e-01\n",
      "             28    2.97307e+03   -2.26217e-03    2.97308e+03    1.77624e-03    5.59324e-01\n",
      "             29    2.95826e+03   -2.24309e-03    2.95826e+03    1.64915e-03    5.60177e-01\n",
      "TrainingResult(timesteps_total=36704, done=None, info={'kl_divergence': 0.0016491478, 'kl_coefficient': 0.15000000000000002, 'rollouts_time': 2.8897347450256348, 'shuffle_time': 0.0010423660278320312, 'load_time': 0.0008578300476074219, 'sgd_time': 1.822683572769165, 'sample_throughput': 2251.076413535893}, episode_reward_mean=181.5, episode_len_mean=181.5, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='0d70d525af4b43409c5fa1d8b2215972', training_iteration=5, timesteps_this_iter=7623, time_this_iter_s=4.724829196929932, time_total_s=25.26203942298889, pid=8668, date='2018-03-28_20-47-02', timestamp=1522295222, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 30, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 128, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [100, 100]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/tune/logger.py:168: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(value, float):\n",
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/tune/logger.py:170: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(value, int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing policy (iterations=30, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    2.92967e+03    3.22774e-03    2.92966e+03    1.41356e-05    5.62545e-01\n",
      "              1    2.91633e+03    2.45404e-03    2.91633e+03    1.54543e-04    5.62640e-01\n",
      "              2    2.90225e+03    1.84078e-03    2.90225e+03    6.59957e-04    5.62127e-01\n",
      "              3    2.88752e+03    1.16049e-03    2.88752e+03    1.60652e-03    5.60807e-01\n",
      "              4    2.87282e+03    6.16450e-04    2.87282e+03    2.68919e-03    5.59769e-01\n",
      "              5    2.85828e+03    4.26363e-05    2.85828e+03    3.63385e-03    5.59570e-01\n",
      "              6    2.84379e+03   -4.11539e-04    2.84379e+03    4.58249e-03    5.58834e-01\n",
      "              7    2.82943e+03   -6.85314e-04    2.82943e+03    5.45573e-03    5.57052e-01\n",
      "              8    2.81516e+03   -7.94172e-04    2.81516e+03    5.61973e-03    5.55575e-01\n",
      "              9    2.80097e+03   -8.39893e-04    2.80097e+03    5.76901e-03    5.55862e-01\n",
      "             10    2.78689e+03   -1.05407e-03    2.78689e+03    6.25555e-03    5.53896e-01\n",
      "             11    2.77290e+03   -1.09525e-03    2.77290e+03    6.49956e-03    5.53162e-01\n",
      "             12    2.75900e+03   -1.22575e-03    2.75900e+03    6.48013e-03    5.53784e-01\n",
      "             13    2.74519e+03   -1.32981e-03    2.74519e+03    6.90602e-03    5.53583e-01\n",
      "             14    2.73146e+03   -1.36004e-03    2.73146e+03    6.61972e-03    5.52023e-01\n",
      "             15    2.71781e+03   -1.39322e-03    2.71781e+03    6.65991e-03    5.52178e-01\n",
      "             16    2.70425e+03   -1.45547e-03    2.70425e+03    6.75865e-03    5.50656e-01\n",
      "             17    2.69078e+03   -1.45672e-03    2.69078e+03    6.78986e-03    5.51748e-01\n",
      "             18    2.67735e+03   -1.53816e-03    2.67735e+03    6.94928e-03    5.49794e-01\n",
      "             19    2.66404e+03   -1.54722e-03    2.66404e+03    6.57974e-03    5.48792e-01\n",
      "             20    2.65078e+03   -1.54569e-03    2.65078e+03    6.52891e-03    5.50274e-01\n",
      "             21    2.63759e+03   -1.59035e-03    2.63759e+03    6.71001e-03    5.48851e-01\n",
      "             22    2.62450e+03   -1.63076e-03    2.62450e+03    7.04286e-03    5.48993e-01\n",
      "             23    2.61146e+03   -1.69115e-03    2.61146e+03    6.74187e-03    5.49828e-01\n",
      "             24    2.59847e+03   -1.66356e-03    2.59847e+03    6.47700e-03    5.48589e-01\n",
      "             25    2.58559e+03   -1.78030e-03    2.58559e+03    7.07249e-03    5.47730e-01\n",
      "             26    2.57275e+03   -1.80360e-03    2.57276e+03    7.18449e-03    5.49276e-01\n",
      "             27    2.55996e+03   -1.77098e-03    2.55996e+03    7.04496e-03    5.47156e-01\n",
      "             28    2.54730e+03   -1.90095e-03    2.54730e+03    7.30712e-03    5.48032e-01\n",
      "             29    2.53462e+03   -1.87050e-03    2.53462e+03    7.18449e-03    5.48576e-01\n",
      "TrainingResult(timesteps_total=44019, done=None, info={'kl_divergence': 0.007184494, 'kl_coefficient': 0.15000000000000002, 'rollouts_time': 2.9068830013275146, 'shuffle_time': 0.0011420249938964844, 'load_time': 0.0009050369262695312, 'sgd_time': 1.8743617534637451, 'sample_throughput': 2281.8434019453694}, episode_reward_mean=192.5, episode_len_mean=192.5, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='0d70d525af4b43409c5fa1d8b2215972', training_iteration=6, timesteps_this_iter=7315, time_this_iter_s=4.792922258377075, time_total_s=30.054961681365967, pid=8668, date='2018-03-28_20-47-07', timestamp=1522295227, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 30, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 128, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [100, 100]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** The current network and training configuration are too large and heavy-duty for a simple problem like CartPole. Modify the configuration to use a smaller network and to speed up the optimization of the surrogate objective (fewer SGD iterations and a larger batch size should help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:47:33.286071Z",
     "start_time": "2018-03-29T03:47:30.520254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Observation shape is (4,)\n",
      "Not using any observation preprocessor.\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 10\n",
    "config['sgd_batchsize'] = 256\n",
    "config['model']['fcnet_hiddens'] = [50, 50]\n",
    "\n",
    "agent = PPOAgent(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Train the agent and try to get a reward of 200. If it's training too slowly you may need to modify the config above to use fewer hidden units, a larger `sgd_batchsize`, a smaller `num_sgd_iter`, or a larger `num_workers`.\n",
    "\n",
    "This should take around 20 or 30 training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:49:37.145810Z",
     "start_time": "2018-03-29T03:48:32.441298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> iteration 6\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    3.72534e+03    2.65221e-03    3.72534e+03    3.72436e-05    6.15637e-01\n",
      "              1    3.72228e+03    1.04352e-03    3.72228e+03    4.07155e-04    6.14076e-01\n",
      "              2    3.71903e+03   -9.03456e-04    3.71903e+03    1.24829e-03    6.12161e-01\n",
      "              3    3.71569e+03   -2.54648e-03    3.71570e+03    2.56542e-03    6.09897e-01\n",
      "              4    3.71229e+03   -4.29543e-03    3.71230e+03    4.23522e-03    6.07125e-01\n",
      "              5    3.70879e+03   -5.87979e-03    3.70880e+03    6.29925e-03    6.04031e-01\n",
      "              6    3.70521e+03   -7.30158e-03    3.70522e+03    8.76495e-03    6.00705e-01\n",
      "              7    3.70149e+03   -8.04212e-03    3.70150e+03    1.05392e-02    5.98145e-01\n",
      "              8    3.69768e+03   -8.18685e-03    3.69768e+03    1.09233e-02    5.96920e-01\n",
      "              9    3.69372e+03   -8.35955e-03    3.69373e+03    1.10945e-02    5.95793e-01\n",
      "TrainingResult(timesteps_total=50540, done=None, info={'kl_divergence': 0.011094497, 'kl_coefficient': 0.05, 'rollouts_time': 2.901832103729248, 'shuffle_time': 0.0011339187622070312, 'load_time': 0.0009429454803466797, 'sgd_time': 0.2863950729370117, 'sample_throughput': 14881.540929781857}, episode_reward_mean=122.16666666666667, episode_len_mean=122.16666666666667, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=7, timesteps_this_iter=7330, time_this_iter_s=3.197577953338623, time_total_s=30.537457704544067, pid=8668, date='2018-03-28_20-48-35', timestamp=1522295315, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/tune/logger.py:168: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(value, float):\n",
      "/Users/alokbeniwal/Library/Python/3.6/lib/python/site-packages/ray/tune/logger.py:170: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(value, int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.95067e+03    7.02002e-05    5.95067e+03    3.74175e-06    6.05889e-01\n",
      "              1    5.94350e+03   -1.08898e-05    5.94350e+03    2.05089e-05    6.06253e-01\n",
      "              2    5.93589e+03   -9.57919e-05    5.93589e+03    5.62319e-05    6.07081e-01\n",
      "              3    5.92806e+03   -2.35799e-04    5.92806e+03    1.11483e-04    6.07741e-01\n",
      "              4    5.92010e+03   -3.19806e-04    5.92010e+03    1.67116e-04    6.08016e-01\n",
      "              5    5.91203e+03   -4.06945e-04    5.91203e+03    2.44078e-04    6.08678e-01\n",
      "              6    5.90378e+03   -5.22747e-04    5.90378e+03    3.27264e-04    6.09033e-01\n",
      "              7    5.89534e+03   -6.06124e-04    5.89534e+03    4.00025e-04    6.09100e-01\n",
      "              8    5.88676e+03   -7.01083e-04    5.88676e+03    5.16007e-04    6.09645e-01\n",
      "              9    5.87804e+03   -7.87193e-04    5.87804e+03    6.62084e-04    6.10110e-01\n",
      "TrainingResult(timesteps_total=58077, done=None, info={'kl_divergence': 0.0006620839, 'kl_coefficient': 0.025, 'rollouts_time': 2.9611079692840576, 'shuffle_time': 0.0012972354888916016, 'load_time': 0.0009298324584960938, 'sgd_time': 0.31947946548461914, 'sample_throughput': 13775.533251641426}, episode_reward_mean=167.48888888888888, episode_len_mean=167.48888888888888, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=8, timesteps_this_iter=7537, time_this_iter_s=3.2901790142059326, time_total_s=33.82763671875, pid=8668, date='2018-03-28_20-48-38', timestamp=1522295318, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 8\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.70831e+03   -1.26502e-03    5.70831e+03    4.19224e-06    5.97682e-01\n",
      "              1    5.69981e+03   -1.45584e-03    5.69981e+03    3.49690e-05    5.96028e-01\n",
      "              2    5.69117e+03   -1.74035e-03    5.69117e+03    9.03664e-05    5.93960e-01\n",
      "              3    5.68237e+03   -1.99478e-03    5.68237e+03    1.54621e-04    5.92256e-01\n",
      "              4    5.67351e+03   -2.23189e-03    5.67351e+03    2.61544e-04    5.90502e-01\n",
      "              5    5.66446e+03   -2.44040e-03    5.66446e+03    4.20517e-04    5.88434e-01\n",
      "              6    5.65526e+03   -2.70550e-03    5.65527e+03    5.96122e-04    5.86363e-01\n",
      "              7    5.64600e+03   -2.92960e-03    5.64600e+03    8.14409e-04    5.84304e-01\n",
      "              8    5.63654e+03   -3.14679e-03    5.63655e+03    1.03855e-03    5.82290e-01\n",
      "              9    5.62693e+03   -3.36748e-03    5.62693e+03    1.30624e-03    5.80279e-01\n",
      "TrainingResult(timesteps_total=65915, done=None, info={'kl_divergence': 0.0013062377, 'kl_coefficient': 0.0125, 'rollouts_time': 3.031008005142212, 'shuffle_time': 0.0011272430419921875, 'load_time': 0.0010046958923339844, 'sgd_time': 0.2960786819458008, 'sample_throughput': 14665.020701472971}, episode_reward_mean=170.3913043478261, episode_len_mean=170.3913043478261, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=9, timesteps_this_iter=7838, time_this_iter_s=3.338526964187622, time_total_s=37.16616368293762, pid=8668, date='2018-03-28_20-48-42', timestamp=1522295322, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 9\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.91202e+03   -1.74113e-04    5.91202e+03    3.19661e-06    5.96756e-01\n",
      "              1    5.89978e+03   -4.17011e-04    5.89978e+03    4.25605e-05    5.95241e-01\n",
      "              2    5.88718e+03   -6.96647e-04    5.88719e+03    1.43904e-04    5.93791e-01\n",
      "              3    5.87452e+03   -9.19206e-04    5.87452e+03    3.14605e-04    5.92168e-01\n",
      "              4    5.86177e+03   -1.21540e-03    5.86177e+03    5.35979e-04    5.90749e-01\n",
      "              5    5.84904e+03   -1.38814e-03    5.84904e+03    8.42264e-04    5.89527e-01\n",
      "              6    5.83624e+03   -1.71973e-03    5.83625e+03    1.22147e-03    5.87848e-01\n",
      "              7    5.82330e+03   -1.92253e-03    5.82330e+03    1.69561e-03    5.86104e-01\n",
      "              8    5.81034e+03   -2.17600e-03    5.81034e+03    2.21193e-03    5.84366e-01\n",
      "              9    5.79730e+03   -2.47968e-03    5.79730e+03    2.66576e-03    5.82994e-01\n",
      "TrainingResult(timesteps_total=73502, done=None, info={'kl_divergence': 0.0026657637, 'kl_coefficient': 0.00625, 'rollouts_time': 2.93464994430542, 'shuffle_time': 0.0010981559753417969, 'load_time': 0.0009348392486572266, 'sgd_time': 0.30565524101257324, 'sample_throughput': 14392.03196852445}, episode_reward_mean=185.0487804878049, episode_len_mean=185.0487804878049, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=10, timesteps_this_iter=7587, time_this_iter_s=3.249396800994873, time_total_s=40.415560483932495, pid=8668, date='2018-03-28_20-48-45', timestamp=1522295325, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 10\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.11059e+03    4.23695e-05    6.11059e+03    7.51192e-07    5.78631e-01\n",
      "              1    6.09360e+03   -2.30874e-05    6.09360e+03    6.40595e-06    5.78382e-01\n",
      "              2    6.07546e+03   -1.17106e-04    6.07546e+03    3.08194e-05    5.78301e-01\n",
      "              3    6.05704e+03   -2.41421e-04    6.05704e+03    7.20931e-05    5.77422e-01\n",
      "              4    6.03877e+03   -3.70973e-04    6.03877e+03    1.28646e-04    5.77234e-01\n",
      "              5    6.02143e+03   -4.66155e-04    6.02143e+03    2.06714e-04    5.76603e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              6    6.00477e+03   -6.06764e-04    6.00477e+03    2.90020e-04    5.76008e-01\n",
      "              7    5.98879e+03   -6.50456e-04    5.98879e+03    4.66421e-04    5.75966e-01\n",
      "              8    5.97369e+03   -8.17682e-04    5.97369e+03    6.22073e-04    5.75581e-01\n",
      "              9    5.95897e+03   -9.35263e-04    5.95897e+03    7.97761e-04    5.74760e-01\n",
      "TrainingResult(timesteps_total=81380, done=None, info={'kl_divergence': 0.00079776125, 'kl_coefficient': 0.003125, 'rollouts_time': 3.1342482566833496, 'shuffle_time': 0.0015649795532226562, 'load_time': 0.001199960708618164, 'sgd_time': 0.32426881790161133, 'sample_throughput': 13963.723151986424}, episode_reward_mean=192.14634146341464, episode_len_mean=192.14634146341464, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=11, timesteps_this_iter=7878, time_this_iter_s=3.470571994781494, time_total_s=43.88613247871399, pid=8668, date='2018-03-28_20-48-49', timestamp=1522295329, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 11\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.14174e+03    3.07195e-04    6.14174e+03    1.32424e-06    5.87532e-01\n",
      "              1    6.12802e+03    2.47561e-04    6.12802e+03    2.30005e-05    5.85934e-01\n",
      "              2    6.11310e+03    9.32813e-05    6.11310e+03    8.02819e-05    5.84098e-01\n",
      "              3    6.09810e+03   -3.18298e-05    6.09810e+03    1.30631e-04    5.82979e-01\n",
      "              4    6.08312e+03   -1.88842e-04    6.08312e+03    2.16624e-04    5.81521e-01\n",
      "              5    6.06823e+03   -2.95265e-04    6.06823e+03    3.20080e-04    5.80119e-01\n",
      "              6    6.05336e+03   -3.56439e-04    6.05336e+03    4.26529e-04    5.78770e-01\n",
      "              7    6.03852e+03   -5.25941e-04    6.03852e+03    5.99628e-04    5.77036e-01\n",
      "              8    6.02382e+03   -6.49507e-04    6.02382e+03    8.07166e-04    5.75199e-01\n",
      "              9    6.00914e+03   -7.64748e-04    6.00914e+03    1.03745e-03    5.73387e-01\n",
      "TrainingResult(timesteps_total=88979, done=None, info={'kl_divergence': 0.001037448, 'kl_coefficient': 0.0015625, 'rollouts_time': 3.0252671241760254, 'shuffle_time': 0.0013039112091064453, 'load_time': 0.0009140968322753906, 'sgd_time': 0.31897664070129395, 'sample_throughput': 13693.792719105155}, episode_reward_mean=194.84615384615384, episode_len_mean=194.84615384615384, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=12, timesteps_this_iter=7599, time_this_iter_s=3.3538928031921387, time_total_s=47.24002528190613, pid=8668, date='2018-03-28_20-48-52', timestamp=1522295332, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 12\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    6.04021e+03    3.29832e-03    6.04021e+03    4.24786e-06    5.67300e-01\n",
      "              1    6.02361e+03    2.97558e-03    6.02361e+03    3.60135e-05    5.65296e-01\n",
      "              2    6.00699e+03    2.62507e-03    6.00699e+03    1.21499e-04    5.63303e-01\n",
      "              3    5.99065e+03    2.23082e-03    5.99064e+03    2.65854e-04    5.61320e-01\n",
      "              4    5.97442e+03    1.86648e-03    5.97442e+03    4.79304e-04    5.58675e-01\n",
      "              5    5.95862e+03    1.47006e-03    5.95862e+03    7.35047e-04    5.56395e-01\n",
      "              6    5.94303e+03    1.11118e-03    5.94303e+03    1.08976e-03    5.54247e-01\n",
      "              7    5.92768e+03    7.50229e-04    5.92768e+03    1.50074e-03    5.52308e-01\n",
      "              8    5.91254e+03    3.62976e-04    5.91254e+03    1.93500e-03    5.50142e-01\n",
      "              9    5.89774e+03    2.76128e-05    5.89774e+03    2.46589e-03    5.47547e-01\n",
      "TrainingResult(timesteps_total=96567, done=None, info={'kl_divergence': 0.0024658907, 'kl_coefficient': 0.00078125, 'rollouts_time': 3.1602611541748047, 'shuffle_time': 0.0013298988342285156, 'load_time': 0.0009489059448242188, 'sgd_time': 0.2915806770324707, 'sample_throughput': 14325.366284593836}, episode_reward_mean=194.56410256410257, episode_len_mean=194.56410256410257, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=13, timesteps_this_iter=7588, time_this_iter_s=3.460909128189087, time_total_s=50.700934410095215, pid=8668, date='2018-03-28_20-48-55', timestamp=1522295335, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 13\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.94481e+03   -4.65109e-03    5.94481e+03    1.53305e-06    5.55137e-01\n",
      "              1    5.93248e+03   -4.93113e-03    5.93249e+03    3.74640e-05    5.53988e-01\n",
      "              2    5.92032e+03   -5.35339e-03    5.92033e+03    1.50852e-04    5.52851e-01\n",
      "              3    5.90834e+03   -5.75565e-03    5.90834e+03    3.60230e-04    5.52091e-01\n",
      "              4    5.89634e+03   -6.18920e-03    5.89635e+03    6.28097e-04    5.51203e-01\n",
      "              5    5.88449e+03   -6.48250e-03    5.88450e+03    1.07370e-03    5.50482e-01\n",
      "              6    5.87271e+03   -7.03707e-03    5.87271e+03    1.51461e-03    5.49583e-01\n",
      "              7    5.86100e+03   -7.39442e-03    5.86101e+03    2.05550e-03    5.48505e-01\n",
      "              8    5.84941e+03   -7.79347e-03    5.84942e+03    2.71153e-03    5.47381e-01\n",
      "              9    5.83793e+03   -8.16144e-03    5.83794e+03    3.50742e-03    5.46350e-01\n",
      "TrainingResult(timesteps_total=103567, done=None, info={'kl_divergence': 0.0035074234, 'kl_coefficient': 0.000390625, 'rollouts_time': 3.037827253341675, 'shuffle_time': 0.0016279220581054688, 'load_time': 0.0011701583862304688, 'sgd_time': 0.3002007007598877, 'sample_throughput': 13324.419263096115}, episode_reward_mean=200.0, episode_len_mean=200.0, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=14, timesteps_this_iter=7000, time_this_iter_s=3.347766876220703, time_total_s=54.04870128631592, pid=8668, date='2018-03-28_20-48-59', timestamp=1522295339, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.64856e+03    1.29332e-04    5.64856e+03    1.96159e-06    5.50513e-01\n",
      "              1    5.63501e+03   -1.42558e-04    5.63501e+03    4.57310e-05    5.50049e-01\n",
      "              2    5.62147e+03   -6.10969e-04    5.62147e+03    1.50330e-04    5.48999e-01\n",
      "              3    5.60824e+03   -8.90095e-04    5.60825e+03    4.84986e-04    5.48259e-01\n",
      "              4    5.59522e+03   -1.47454e-03    5.59522e+03    7.58791e-04    5.47077e-01\n",
      "              5    5.58244e+03   -1.90128e-03    5.58244e+03    1.17708e-03    5.45979e-01\n",
      "              6    5.56989e+03   -2.31896e-03    5.56989e+03    1.65945e-03    5.44985e-01\n",
      "              7    5.55752e+03   -2.66542e-03    5.55752e+03    2.41435e-03    5.44046e-01\n",
      "              8    5.54535e+03   -3.11905e-03    5.54535e+03    3.24475e-03    5.42890e-01\n",
      "              9    5.53337e+03   -3.39559e-03    5.53337e+03    4.36151e-03    5.41924e-01\n",
      "TrainingResult(timesteps_total=111237, done=None, info={'kl_divergence': 0.0043615135, 'kl_coefficient': 0.0001953125, 'rollouts_time': 3.06192684173584, 'shuffle_time': 0.0013461112976074219, 'load_time': 0.0009679794311523438, 'sgd_time': 0.3087325096130371, 'sample_throughput': 14514.18253819933}, episode_reward_mean=196.66666666666666, episode_len_mean=196.66666666666666, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=15, timesteps_this_iter=7670, time_this_iter_s=3.3802690505981445, time_total_s=57.42897033691406, pid=8668, date='2018-03-28_20-49-02', timestamp=1522295342, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 15\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.71610e+03    9.37536e-05    5.71610e+03    7.80498e-07    5.48235e-01\n",
      "              1    5.70326e+03   -4.83041e-05    5.70326e+03    1.20687e-05    5.49532e-01\n",
      "              2    5.69035e+03   -3.56541e-04    5.69035e+03    6.00490e-05    5.51620e-01\n",
      "              3    5.67774e+03   -6.07330e-04    5.67774e+03    1.42086e-04    5.53284e-01\n",
      "              4    5.66556e+03   -8.59345e-04    5.66556e+03    2.71757e-04    5.55198e-01\n",
      "              5    5.65376e+03   -1.14323e-03    5.65376e+03    4.48633e-04    5.57040e-01\n",
      "              6    5.64232e+03   -1.39931e-03    5.64232e+03    6.65131e-04    5.58945e-01\n",
      "              7    5.63118e+03   -1.67655e-03    5.63118e+03    9.50972e-04    5.60861e-01\n",
      "              8    5.62030e+03   -1.96081e-03    5.62030e+03    1.24443e-03    5.62537e-01\n",
      "              9    5.60966e+03   -2.21172e-03    5.60966e+03    1.59008e-03    5.64206e-01\n",
      "TrainingResult(timesteps_total=118237, done=None, info={'kl_divergence': 0.0015900803, 'kl_coefficient': 9.765625e-05, 'rollouts_time': 2.9175848960876465, 'shuffle_time': 0.0009510517120361328, 'load_time': 0.0009698867797851562, 'sgd_time': 0.29549288749694824, 'sample_throughput': 13536.704838763033}, episode_reward_mean=200.0, episode_len_mean=200.0, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=16, timesteps_this_iter=7000, time_this_iter_s=3.222285032272339, time_total_s=60.6512553691864, pid=8668, date='2018-03-28_20-49-05', timestamp=1522295345, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 16\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.54138e+03   -1.12251e-03    5.54138e+03    1.22874e-05    5.52887e-01\n",
      "              1    5.53155e+03   -1.28658e-03    5.53155e+03    3.30230e-05    5.53715e-01\n",
      "              2    5.52184e+03   -1.37431e-03    5.52185e+03    5.42088e-05    5.54218e-01\n",
      "              3    5.51217e+03   -1.47548e-03    5.51217e+03    8.21702e-05    5.54521e-01\n",
      "              4    5.50263e+03   -1.55850e-03    5.50263e+03    1.62124e-04    5.55091e-01\n",
      "              5    5.49313e+03   -1.69262e-03    5.49313e+03    2.66764e-04    5.55643e-01\n",
      "              6    5.48371e+03   -1.80195e-03    5.48371e+03    3.70078e-04    5.55973e-01\n",
      "              7    5.47434e+03   -1.91430e-03    5.47434e+03    4.72598e-04    5.56385e-01\n",
      "              8    5.46509e+03   -1.91917e-03    5.46510e+03    6.82890e-04    5.56685e-01\n",
      "              9    5.45595e+03   -2.10537e-03    5.45596e+03    7.76852e-04    5.57018e-01\n",
      "TrainingResult(timesteps_total=125591, done=None, info={'kl_divergence': 0.0007768519, 'kl_coefficient': 4.8828125e-05, 'rollouts_time': 2.9962522983551025, 'shuffle_time': 0.0010607242584228516, 'load_time': 0.0009620189666748047, 'sgd_time': 0.289858341217041, 'sample_throughput': 14393.237684597378}, episode_reward_mean=198.75675675675674, episode_len_mean=198.75675675675674, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=17, timesteps_this_iter=7354, time_this_iter_s=3.2952089309692383, time_total_s=63.94646430015564, pid=8668, date='2018-03-28_20-49-09', timestamp=1522295349, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 17\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.50602e+03    1.28746e-03    5.50602e+03    3.35345e-06    5.53366e-01\n",
      "              1    5.49735e+03    1.21170e-03    5.49735e+03    5.18968e-06    5.52908e-01\n",
      "              2    5.48870e+03    1.11103e-03    5.48870e+03    2.04613e-05    5.52079e-01\n",
      "              3    5.48011e+03    1.02558e-03    5.48011e+03    5.02862e-05    5.51219e-01\n",
      "              4    5.47159e+03    9.43956e-04    5.47159e+03    9.95146e-05    5.50234e-01\n",
      "              5    5.46312e+03    8.58085e-04    5.46312e+03    2.01335e-04    5.48821e-01\n",
      "              6    5.45469e+03    7.44366e-04    5.45469e+03    2.98226e-04    5.47804e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              7    5.44629e+03    6.78124e-04    5.44629e+03    4.45216e-04    5.46537e-01\n",
      "              8    5.43798e+03    5.61219e-04    5.43798e+03    5.98634e-04    5.45495e-01\n",
      "              9    5.42974e+03    4.70412e-04    5.42974e+03    7.50912e-04    5.44430e-01\n",
      "TrainingResult(timesteps_total=132591, done=None, info={'kl_divergence': 0.00075091206, 'kl_coefficient': 2.44140625e-05, 'rollouts_time': 2.7159507274627686, 'shuffle_time': 0.0010960102081298828, 'load_time': 0.00086212158203125, 'sgd_time': 0.2708714008331299, 'sample_throughput': 14767.155143352313}, episode_reward_mean=200.0, episode_len_mean=200.0, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=18, timesteps_this_iter=7000, time_this_iter_s=2.995709180831909, time_total_s=66.94217348098755, pid=8668, date='2018-03-28_20-49-12', timestamp=1522295352, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 18\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.34988e+03    2.60188e-03    5.34988e+03    1.38953e-06    5.48837e-01\n",
      "              1    5.34121e+03    2.60344e-03    5.34121e+03    6.19546e-06    5.48072e-01\n",
      "              2    5.33266e+03    2.58083e-03    5.33265e+03    4.18766e-06    5.48036e-01\n",
      "              3    5.32414e+03    2.55648e-03    5.32413e+03    6.08863e-06    5.47716e-01\n",
      "              4    5.31576e+03    2.52438e-03    5.31576e+03    1.03328e-05    5.47274e-01\n",
      "              5    5.30744e+03    2.49591e-03    5.30744e+03    1.11669e-05    5.47170e-01\n",
      "              6    5.29921e+03    2.48005e-03    5.29920e+03    1.49497e-05    5.46948e-01\n",
      "              7    5.29103e+03    2.44068e-03    5.29103e+03    2.38067e-05    5.46349e-01\n",
      "              8    5.28293e+03    2.43891e-03    5.28293e+03    3.05065e-05    5.46220e-01\n",
      "              9    5.27491e+03    2.39764e-03    5.27491e+03    4.47835e-05    5.45994e-01\n",
      "TrainingResult(timesteps_total=139957, done=None, info={'kl_divergence': 4.4783475e-05, 'kl_coefficient': 1.220703125e-05, 'rollouts_time': 2.8302500247955322, 'shuffle_time': 0.001049041748046875, 'load_time': 0.0009920597076416016, 'sgd_time': 0.2922854423522949, 'sample_throughput': 14256.611504371362}, episode_reward_mean=199.0810810810811, episode_len_mean=199.0810810810811, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=19, timesteps_this_iter=7366, time_this_iter_s=3.1314938068389893, time_total_s=70.07366728782654, pid=8668, date='2018-03-28_20-49-15', timestamp=1522295355, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 19\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.31539e+03    9.04697e-04    5.31539e+03    8.74990e-07    5.45384e-01\n",
      "              1    5.30696e+03    5.69211e-04    5.30696e+03    2.40689e-05    5.44240e-01\n",
      "              2    5.29852e+03    1.30672e-04    5.29852e+03    1.33425e-04    5.43649e-01\n",
      "              3    5.29016e+03   -2.91893e-04    5.29016e+03    4.29326e-04    5.43599e-01\n",
      "              4    5.28189e+03   -8.24879e-04    5.28189e+03    8.11042e-04    5.42964e-01\n",
      "              5    5.27357e+03   -1.15598e-03    5.27357e+03    1.36903e-03    5.42429e-01\n",
      "              6    5.26532e+03   -1.67120e-03    5.26532e+03    1.91875e-03    5.41382e-01\n",
      "              7    5.25717e+03   -2.06292e-03    5.25718e+03    2.48895e-03    5.40377e-01\n",
      "              8    5.24905e+03   -2.40950e-03    5.24905e+03    3.32438e-03    5.39725e-01\n",
      "              9    5.24098e+03   -2.79034e-03    5.24099e+03    4.35719e-03    5.38509e-01\n",
      "TrainingResult(timesteps_total=147351, done=None, info={'kl_divergence': 0.0043571885, 'kl_coefficient': 6.103515625e-06, 'rollouts_time': 2.9728939533233643, 'shuffle_time': 0.0014061927795410156, 'load_time': 0.0009088516235351562, 'sgd_time': 0.31879448890686035, 'sample_throughput': 13783.174279665041}, episode_reward_mean=199.83783783783784, episode_len_mean=199.83783783783784, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=20, timesteps_this_iter=7394, time_this_iter_s=3.3010149002075195, time_total_s=73.37468218803406, pid=8668, date='2018-03-28_20-49-18', timestamp=1522295358, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 20\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.25117e+03   -1.27383e-03    5.25117e+03    6.40853e-07    5.43524e-01\n",
      "              1    5.24413e+03   -1.30413e-03    5.24413e+03    6.30196e-06    5.42653e-01\n",
      "              2    5.23714e+03   -1.35922e-03    5.23714e+03    1.76367e-05    5.41941e-01\n",
      "              3    5.23014e+03   -1.41521e-03    5.23014e+03    3.54020e-05    5.40941e-01\n",
      "              4    5.22324e+03   -1.44355e-03    5.22324e+03    5.92264e-05    5.40124e-01\n",
      "              5    5.21632e+03   -1.44276e-03    5.21632e+03    9.66760e-05    5.38679e-01\n",
      "              6    5.20944e+03   -1.54202e-03    5.20944e+03    1.28767e-04    5.37826e-01\n",
      "              7    5.20258e+03   -1.59940e-03    5.20258e+03    1.63574e-04    5.37138e-01\n",
      "              8    5.19575e+03   -1.63127e-03    5.19575e+03    2.10893e-04    5.36365e-01\n",
      "              9    5.18897e+03   -1.65263e-03    5.18897e+03    2.48193e-04    5.35469e-01\n",
      "TrainingResult(timesteps_total=154533, done=None, info={'kl_divergence': 0.00024819296, 'kl_coefficient': 3.0517578125e-06, 'rollouts_time': 2.9703617095947266, 'shuffle_time': 0.0012521743774414062, 'load_time': 0.0009360313415527344, 'sgd_time': 0.272449254989624, 'sample_throughput': 14681.633099537514}, episode_reward_mean=199.5, episode_len_mean=199.5, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=21, timesteps_this_iter=7182, time_this_iter_s=3.2531661987304688, time_total_s=76.62784838676453, pid=8668, date='2018-03-28_20-49-21', timestamp=1522295361, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.17134e+03   -2.74704e-04    5.17134e+03    2.76425e-06    5.32934e-01\n",
      "              1    5.16472e+03   -3.73292e-04    5.16472e+03    1.32440e-05    5.32601e-01\n",
      "              2    5.15815e+03   -4.25899e-04    5.15815e+03    3.93870e-05    5.32371e-01\n",
      "              3    5.15160e+03   -5.37482e-04    5.15160e+03    7.35631e-05    5.31598e-01\n",
      "              4    5.14507e+03   -6.53202e-04    5.14507e+03    1.11934e-04    5.31666e-01\n",
      "              5    5.13859e+03   -7.18052e-04    5.13859e+03    1.40243e-04    5.30932e-01\n",
      "              6    5.13211e+03   -8.22091e-04    5.13211e+03    1.92913e-04    5.30676e-01\n",
      "              7    5.12564e+03   -8.75232e-04    5.12564e+03    2.88889e-04    5.30042e-01\n",
      "              8    5.11919e+03   -1.00700e-03    5.11919e+03    3.83385e-04    5.29917e-01\n",
      "              9    5.11279e+03   -1.10125e-03    5.11279e+03    5.02132e-04    5.29780e-01\n",
      "TrainingResult(timesteps_total=161533, done=None, info={'kl_divergence': 0.00050213176, 'kl_coefficient': 1.52587890625e-06, 'rollouts_time': 2.887260913848877, 'shuffle_time': 0.0010800361633300781, 'load_time': 0.0009179115295410156, 'sgd_time': 0.27464866638183594, 'sample_throughput': 14564.06125212681}, episode_reward_mean=200.0, episode_len_mean=200.0, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=22, timesteps_this_iter=7000, time_this_iter_s=3.171172857284546, time_total_s=79.79902124404907, pid=8668, date='2018-03-28_20-49-24', timestamp=1522295364, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 22\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.07862e+03    8.92996e-04    5.07861e+03    7.93723e-07    5.32074e-01\n",
      "              1    5.07192e+03    8.06260e-04    5.07192e+03    1.07957e-05    5.30796e-01\n",
      "              2    5.06529e+03    7.18489e-04    5.06529e+03    5.39098e-05    5.30206e-01\n",
      "              3    5.05867e+03    5.33640e-04    5.05867e+03    1.13169e-04    5.29274e-01\n",
      "              4    5.05212e+03    4.31718e-04    5.05212e+03    1.59299e-04    5.28578e-01\n",
      "              5    5.04556e+03    3.31618e-04    5.04556e+03    2.78205e-04    5.27829e-01\n",
      "              6    5.03902e+03    2.38533e-04    5.03902e+03    4.38753e-04    5.26923e-01\n",
      "              7    5.03252e+03    8.87514e-05    5.03252e+03    5.71734e-04    5.26323e-01\n",
      "              8    5.02601e+03   -2.82261e-05    5.02601e+03    7.14958e-04    5.25656e-01\n",
      "              9    5.01955e+03   -1.18265e-04    5.01955e+03    8.96966e-04    5.25520e-01\n",
      "TrainingResult(timesteps_total=168718, done=None, info={'kl_divergence': 0.0008969656, 'kl_coefficient': 7.62939453125e-07, 'rollouts_time': 2.7975802421569824, 'shuffle_time': 0.0010249614715576172, 'load_time': 0.001013040542602539, 'sgd_time': 0.2852344512939453, 'sample_throughput': 14672.140693436759}, episode_reward_mean=199.58333333333334, episode_len_mean=199.58333333333334, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=23, timesteps_this_iter=7185, time_this_iter_s=3.092319965362549, time_total_s=82.89134120941162, pid=8668, date='2018-03-28_20-49-28', timestamp=1522295368, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 23\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    5.03159e+03    3.92972e-03    5.03158e+03    1.30170e-06    5.23398e-01\n",
      "              1    5.02555e+03    3.81055e-03    5.02555e+03    1.63897e-05    5.24389e-01\n",
      "              2    5.01952e+03    3.68997e-03    5.01951e+03    7.08850e-05    5.25947e-01\n",
      "              3    5.01359e+03    3.53952e-03    5.01359e+03    1.74194e-04    5.28392e-01\n",
      "              4    5.00759e+03    3.23402e-03    5.00759e+03    2.87972e-04    5.29995e-01\n",
      "              5    5.00168e+03    3.09196e-03    5.00168e+03    4.46588e-04    5.31651e-01\n",
      "              6    4.99579e+03    2.95098e-03    4.99579e+03    7.07762e-04    5.33683e-01\n",
      "              7    4.98989e+03    2.67616e-03    4.98989e+03    9.37590e-04    5.35196e-01\n",
      "              8    4.98400e+03    2.52647e-03    4.98399e+03    1.22494e-03    5.36619e-01\n",
      "              9    4.97815e+03    2.37393e-03    4.97815e+03    1.55303e-03    5.38603e-01\n",
      "TrainingResult(timesteps_total=175718, done=None, info={'kl_divergence': 0.0015530278, 'kl_coefficient': 3.814697265625e-07, 'rollouts_time': 2.767934799194336, 'shuffle_time': 0.0012722015380859375, 'load_time': 0.0008997917175292969, 'sgd_time': 0.270521879196167, 'sample_throughput': 14786.23471005622}, episode_reward_mean=200.0, episode_len_mean=200.0, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=24, timesteps_this_iter=7000, time_this_iter_s=3.047487258911133, time_total_s=85.93882846832275, pid=8668, date='2018-03-28_20-49-31', timestamp=1522295371, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 24\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    4.96129e+03    3.87908e-03    4.96129e+03    2.89463e-06    5.33487e-01\n",
      "              1    4.95545e+03    3.81434e-03    4.95545e+03    8.82634e-06    5.33277e-01\n",
      "              2    4.94960e+03    3.72124e-03    4.94960e+03    3.82631e-05    5.32453e-01\n",
      "              3    4.94381e+03    3.65835e-03    4.94381e+03    1.20042e-04    5.31597e-01\n",
      "              4    4.93801e+03    3.50567e-03    4.93800e+03    1.81362e-04    5.31069e-01\n",
      "              5    4.93226e+03    3.44692e-03    4.93226e+03    2.68756e-04    5.30661e-01\n",
      "              6    4.92651e+03    3.45627e-03    4.92650e+03    4.85428e-04    5.29558e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              7    4.92075e+03    3.20098e-03    4.92075e+03    6.01013e-04    5.28943e-01\n",
      "              8    4.91498e+03    3.16703e-03    4.91498e+03    6.94038e-04    5.28366e-01\n",
      "              9    4.90927e+03    3.07371e-03    4.90927e+03    8.10775e-04    5.27563e-01\n",
      "TrainingResult(timesteps_total=182735, done=None, info={'kl_divergence': 0.0008107755, 'kl_coefficient': 1.9073486328125e-07, 'rollouts_time': 2.73003888130188, 'shuffle_time': 0.0009980201721191406, 'load_time': 0.0009150505065917969, 'sgd_time': 0.27130842208862305, 'sample_throughput': 14806.027653236082}, episode_reward_mean=194.91666666666666, episode_len_mean=194.91666666666666, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=25, timesteps_this_iter=7017, time_this_iter_s=3.0101749897003174, time_total_s=88.94900345802307, pid=8668, date='2018-03-28_20-49-34', timestamp=1522295374, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n",
      "===> iteration 25\n",
      "Computing policy (iterations=10, stepsize=5e-05):\n",
      "           iter     total loss    policy loss        vf loss             kl        entropy\n",
      "              0    4.93095e+03   -6.90576e-04    4.93095e+03    1.54785e-06    5.27387e-01\n",
      "              1    4.92540e+03   -7.35809e-04    4.92540e+03    7.08835e-06    5.27721e-01\n",
      "              2    4.91985e+03   -8.01253e-04    4.91986e+03    1.57251e-05    5.28378e-01\n",
      "              3    4.91435e+03   -8.70085e-04    4.91435e+03    3.59778e-05    5.29250e-01\n",
      "              4    4.90885e+03   -9.31902e-04    4.90885e+03    5.20069e-05    5.29626e-01\n",
      "              5    4.90340e+03   -9.62504e-04    4.90340e+03    1.02727e-04    5.30668e-01\n",
      "              6    4.89794e+03   -1.08165e-03    4.89795e+03    1.41060e-04    5.31297e-01\n",
      "              7    4.89247e+03   -1.11931e-03    4.89247e+03    1.97324e-04    5.32131e-01\n",
      "              8    4.88703e+03   -1.20891e-03    4.88703e+03    2.50303e-04    5.32599e-01\n",
      "              9    4.88158e+03   -1.25983e-03    4.88158e+03    3.40725e-04    5.33534e-01\n",
      "TrainingResult(timesteps_total=189930, done=None, info={'kl_divergence': 0.00034072495, 'kl_coefficient': 9.5367431640625e-08, 'rollouts_time': 2.7147457599639893, 'shuffle_time': 0.0010869503021240234, 'load_time': 0.0008823871612548828, 'sgd_time': 0.27179694175720215, 'sample_throughput': 14716.869049885132}, episode_reward_mean=199.86111111111111, episode_len_mean=199.86111111111111, episodes_total=None, mean_accuracy=None, mean_validation_accuracy=None, mean_loss=None, neg_mean_loss=None, experiment_id='e3efea1e166e44919724746e8ca51e8a', training_iteration=26, timesteps_this_iter=7195, time_this_iter_s=2.9956650733947754, time_total_s=91.94466853141785, pid=8668, date='2018-03-28_20-49-37', timestamp=1522295377, hostname='DILBAG-M-X2Y6', config={'gamma': 0.995, 'horizon': 2000, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'num_sgd_iter': 10, 'sgd_stepsize': 5e-05, 'devices': ['/cpu:0', '/cpu:1', '/cpu:2', '/cpu:3'], 'tf_session_args': {'device_count': {'CPU': 4}, 'log_device_placement': False, 'allow_soft_placement': True}, 'rollout_batchsize': 1, 'sgd_batchsize': 256, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'kl_target': 0.01, 'model': {'free_log_std': False, 'fcnet_hiddens': [50, 50]}, 'observation_filter': 'MeanStdFilter', 'extra_frameskip': 1, 'timesteps_per_batch': 4000, 'min_steps_per_task': 1000, 'num_workers': 3, 'worker_resources': {'num_cpus': 1}, 'full_trace_nth_sgd_batch': -1, 'full_trace_data_load': False, 'tf_debug_iteration': -1, 'tf_debug_inf_or_nan': False, 'write_logs': True, 'env_config': {}, 'env': 'CartPole-v0'})\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    result = agent.train()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint the current model. The call to `agent.save()` returns the path to the checkpointed model and can be used later to restore the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T04:18:20.338196Z",
     "start_time": "2018-03-29T04:18:19.849877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/alokbeniwal/ray_results/2018-03-28_20-47-3088_z_7cy/checkpoint-26 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = agent.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the trained policy to make predictions.\n",
    "\n",
    "**NOTE:** Here we are loading the trained policy in the same process, but in practice, this would often be done in a different process (probably on a different machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T04:18:48.427895Z",
     "start_time": "2018-03-29T04:18:34.564905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Observation shape is (4,)\n",
      "Not using any observation preprocessor.\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "Constructing fcnet [50, 50] <function tanh at 0x11cf7f378>\n",
      "INFO:tensorflow:Restoring parameters from /Users/alokbeniwal/ray_results/2018-03-28_20-47-3088_z_7cy/checkpoint-26\n"
     ]
    }
   ],
   "source": [
    "trained_config = config.copy()\n",
    "\n",
    "test_agent = PPOAgent(trained_config, 'CartPole-v0')\n",
    "test_agent.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the trained policy to act in an environment. The key line is the call to `test_agent.compute_action(state)` which uses the trained policy to choose an action.\n",
    "\n",
    "**EXERCISE:** Verify that the reward received roughly matches up with the reward printed in the training logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T04:20:03.212295Z",
     "start_time": "2018-03-29T04:20:03.052475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "200.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action = test_agent.compute_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(cumulative_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
